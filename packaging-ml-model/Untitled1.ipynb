{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=[\"id\", \"Surname\", \"CustomerId\"],inplace=True)\n",
    "test.drop(columns=[\"id\", \"Surname\"],inplace=True)\n",
    "y_target=train_copy['Exited']\n",
    "Xtrain_copy = train_copy.drop(target, axis =1)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xtrain_copy, y_target,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=0,\n",
    "                                                        stratify=y_target)\n",
    "####  \n",
    "def store_missing_rows(df, features):\n",
    "    '''Fonction qui stocke les lignes contenant des valeurs manquantes pour un ensemble donné de fonctionnalités'''\n",
    "    missing_rows = {}\n",
    "    # Grouper les lignes par feature manquante et collecter les index des lignes\n",
    "    for feature in features:\n",
    "        missing_indices = df.index[df[feature].isnull()].tolist()\n",
    "        if missing_indices:\n",
    "            missing_rows[feature] = missing_indices\n",
    "    return missing_rows\n",
    "\n",
    "##### \n",
    "\n",
    "def fill_missing(train, test, target, max_iterations=10):\n",
    "    '''\n",
    "    Iterative Missing Imputer: Updates filled missing values iteratively using KNN \n",
    "    imputation for numerical variables and mode imputation for categorical variables\n",
    "    \n",
    "    '''\n",
    "    # Copie du DataFrame train\n",
    "    train_temp = train.copy()\n",
    "    if target in train_temp.columns:\n",
    "        train_temp = train_temp.drop(columns=target)\n",
    "    \n",
    "    # Concaténation de train et test\n",
    "    df = pd.concat([train_temp, test], axis=\"rows\").reset_index(drop=True)\n",
    "    \n",
    "    # Sélection des caractéristiques avec des valeurs manquantes\n",
    "    numeric_features = df.select_dtypes(include=np.number).columns\n",
    "    categorical_features = df.select_dtypes(include='object').columns\n",
    "    \n",
    "    # Imputation des valeurs manquantes pour les variables numériques avec KNNImputer\n",
    "    if len(numeric_features) > 0:\n",
    "        imputer_numeric = KNNImputer()\n",
    "        df[numeric_features] = imputer_numeric.fit_transform(df[numeric_features])\n",
    "    \n",
    "    # Imputation des valeurs manquantes pour les variables catégorielles avec le mode\n",
    "    if len(categorical_features) > 0:\n",
    "        for feature in categorical_features:\n",
    "            mode_value = df[feature].mode()[0]\n",
    "            df[feature] = df[feature].fillna(mode_value)\n",
    "    \n",
    "    # Séparation des données train et test\n",
    "    train[numeric_features] = df.iloc[:train.shape[0]][numeric_features].values\n",
    "    test[numeric_features] = df.iloc[train.shape[0]:][numeric_features].values\n",
    "    \n",
    "    train[categorical_features] = df.iloc[:train.shape[0]][categorical_features].values\n",
    "    test[categorical_features] = df.iloc[train.shape[0]:][categorical_features].values\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# Fonction pour obtenir la valeur la plus proche dans une liste\n",
    "def nearest_val(target, common):\n",
    "    return min(common, key=lambda x: abs(x - target))\n",
    "\n",
    "# Fonction pour traiter les valeurs catégorielles rares\n",
    "\n",
    "def handle_rare_categories(train, test, col_list):\n",
    "    for col in col_list:\n",
    "        uncommon = set(test[col].unique()) | set(train[col].unique())\n",
    "        common = set(test[col].unique()) & set(train[col].unique())\n",
    "        uncommon -= common\n",
    "        if uncommon:\n",
    "            train[col] = train[col].apply(lambda x: nearest_val(x, common) if x not in common else x)\n",
    "            test[col] = test[col].apply(lambda x: nearest_val(x, common) if x not in common else x)\n",
    "    return train, test\n",
    "\n",
    "def OHE(train, test, col, min_percentage=0.0):\n",
    "    \"\"\"\n",
    "    One-Hot Encoding function optimized for feature encoding in train and test datasets.\n",
    "    Removes the category with the least frequency within each column if it represents less than min_percentage.\n",
    "\n",
    "    Parameters:\n",
    "    train (pd.DataFrame): Training dataset.\n",
    "    test (pd.DataFrame): Test dataset.\n",
    "    cols (list): List of column names to perform one-hot encoding.\n",
    "    target_col (str): Name of the target column (to be excluded from test after encoding).\n",
    "    min_percentage (float): Minimum percentage threshold for category frequency. Default is 0.0.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Encoded training dataset.\n",
    "    pd.DataFrame: Encoded test dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy original dataframes to avoid modifying input data\n",
    "    train_encode = pd.DataFrame(index=train.index)\n",
    "    test_encode = pd.DataFrame(index=test.index)\n",
    "    ohe = \"OHE\"\n",
    "\n",
    "    train_value_counts = train[col].value_counts(normalize=True)\n",
    "    min_freq_category = train_value_counts.idxmin()\n",
    "    min_freq_percentage = train_value_counts.min()\n",
    "\n",
    "    if min_freq_percentage < min_percentage:\n",
    "        min_freq_category_name = f\"{col}_{ohe}_{min_freq_category}\"\n",
    "        train_encode = pd.concat([\n",
    "            train_encode,\n",
    "            pd.get_dummies(train[col], prefix=f\"{col}_OHE\", prefix_sep='_')\n",
    "            .drop(columns=min_freq_category_name)\n",
    "        ], axis=1)\n",
    "\n",
    "        test_encode = pd.concat([\n",
    "            test_encode,\n",
    "            pd.get_dummies(test[col], prefix=f\"{col}_OHE\", prefix_sep='_')\n",
    "            .drop(columns=min_freq_category_name)\n",
    "        ], axis=1)\n",
    "    else:\n",
    "        train_encode = pd.concat([\n",
    "            train_encode,\n",
    "            pd.get_dummies(train[col], prefix=f\"{col}_OHE\", prefix_sep='_')\n",
    "        ], axis=1)\n",
    "\n",
    "        test_encode = pd.concat([\n",
    "            test_encode,\n",
    "            pd.get_dummies(test[col], prefix=f\"{col}_OHE\", prefix_sep='_')\n",
    "        ], axis=1)\n",
    "    return train_encode, test_encode\n",
    "\n",
    "def cat_encoding(Xtrain, Xtest, cols_to_encode):\n",
    "    Xtrain_encode = Xtrain.copy()\n",
    "    Xtest_encode = Xtest.copy()\n",
    "    for col in cols_to_encode:\n",
    "        OHE_train, OHE_test = OHE(Xtrain, Xtest, col, min_percentage=0.005)\n",
    "        Xtrain_encode = pd.concat([Xtrain_encode, OHE_train], axis = 1).drop(col, axis = 1)\n",
    "        Xtest_encode = pd.concat([Xtest_encode, OHE_test], axis = 1).drop(col, axis = 1)    \n",
    "    return   Xtrain_encode, Xtest_encode\n",
    "\n",
    "def apply_transformations(train, test, col, transformations):\n",
    "    for transformation in transformations:\n",
    "        name = transformation[\"name\"]\n",
    "        func = transformation[\"func\"]\n",
    "        train[name] = func(train[col].to_numpy().reshape(-1, 1)) \n",
    "        test[name] = func(test[col].to_numpy().reshape(-1, 1)) \n",
    "        \n",
    "def transformer(Xtrain, Xtest, Ytrain, cont_cols, target):\n",
    "    global unimportant_features, overall_best_score, overall_best_col\n",
    "    unimportant_features = []\n",
    "    overall_best_score = 0\n",
    "    overall_best_col = 'none'\n",
    "    table = pd.DataFrame(columns=['Feature', 'Initial ROC_AUC', 'Transformation', 'Transformed ROC_AUC'])\n",
    "\n",
    "    for col in cont_cols:\n",
    "        # {\"name\": \"bx_cx_\" + col, \"func\": lambda x: PowerTransformer(method='box-cox').fit_transform(x)},\n",
    "        transformations = [\n",
    "            {\"name\": \"log_\" + col, \"func\": lambda x: np.log1p(x)},\n",
    "            {\"name\": \"sqrt_\" + col, \"func\": lambda x: np.sqrt(x)},\n",
    "            {\"name\": \"y_J_\" + col, \"func\": lambda x: PowerTransformer(method='yeo-johnson').fit_transform(x)},\n",
    "            {\"name\": \"pow_\" + col, \"func\": lambda x: FunctionTransformer(lambda x: np.power(x + 1 - np.min(x), 0.25)).fit_transform(x)},\n",
    "            {\"name\": \"pow2_\" + col, \"func\": lambda x: FunctionTransformer(lambda x: np.power(x + 1 - np.min(x), 2)).fit_transform(x)},\n",
    "            {\"name\": \"log_sqrt\" + col, \"func\": lambda x: np.log1p(np.sqrt(x))}\n",
    "        ]\n",
    "        #Xtrain, Xtest = fill_missing_numerical(Xtrain, Xtest, target, max_iterations=10)\n",
    "        apply_transformations(Xtrain, Xtest, col, transformations) \n",
    "        \n",
    "        temp_cols = [transformation[\"name\"] for transformation in transformations] + [col]\n",
    "        auc_scores = []\n",
    "        \n",
    "        for f in temp_cols:\n",
    "            X = Xtrain[[f]]\n",
    "            y = Ytrain            \n",
    "            kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            auc = []\n",
    "            for train_idx, val_idx in kf.split(X, y):\n",
    "                X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "                X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]                \n",
    "                model = LogisticRegression()\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict_proba(X_val)[:,1]\n",
    "                auc.append(roc_auc_score(y_val, y_pred))\n",
    "            auc_scores.append((f, np.mean(auc)))\n",
    "        best_col, best_auc = sorted(auc_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "        \n",
    "        if best_auc > overall_best_score:\n",
    "            overall_best_score = best_auc\n",
    "            overall_best_col = best_col\n",
    "            \n",
    "        cols_to_drop = [f for f in temp_cols if f != best_col]\n",
    "        final_selection = [f for f in temp_cols if f not in cols_to_drop]\n",
    "        \n",
    "        if cols_to_drop:\n",
    "            unimportant_features += cols_to_drop\n",
    "        table.loc[len(table)] = [col, np.mean(auc), best_col, best_auc]\n",
    "        \n",
    "    Xtrain = Xtrain.drop(unimportant_features, axis = 1)\n",
    "    Xtest  = Xtest.drop(unimportant_features, axis = 1)\n",
    "\n",
    "    print(table)\n",
    "    print(\"Overall best CV ROC AUC score:\", overall_best_score)\n",
    "    return Xtrain, Xtest, unimportant_features\n",
    "\n",
    "def generate_features(col1, col2):\n",
    "        temp_df = pd.DataFrame()  # Temporary dataframe to store the generated columns\n",
    "        temp_df_test = pd.DataFrame()  # Temporary dataframe for test data\n",
    "\n",
    "        operations = [('*', lambda x, y: x * y),\n",
    "                      ('/', lambda x, y: x / (y + 1e-5)),\n",
    "                      ('/', lambda x, y: y / (x + 1e-5)),\n",
    "                      ('-', lambda x, y: x - y),\n",
    "                      ('+', lambda x, y: x + y)]\n",
    "\n",
    "        for op_name, operation in operations:\n",
    "            new_col_name = f\"{col1}{op_name}{col2}\"\n",
    "            temp_df[new_col_name] = operation(Xtrain[col1], Xtrain[col2])\n",
    "            temp_df_test[new_col_name] = operation(Xtest[col1], Xtest[col2])\n",
    "\n",
    "        return temp_df, temp_df_test\n",
    "    \n",
    "    \n",
    "def better_features(Xtrain, Xtest, Ytrain, cols, best_score):\n",
    "    new_cols = []\n",
    "    skf = KFold(n_splits=5, shuffle=True, random_state=42)  # Stratified k-fold object\n",
    "    \n",
    "    def generate_features(col1, col2):\n",
    "        temp_df = pd.DataFrame()  # Temporary dataframe to store the generated columns\n",
    "        temp_df_test = pd.DataFrame()  # Temporary dataframe for test data\n",
    "\n",
    "        operations = [('*', lambda x, y: x * y),\n",
    "                      ('/', lambda x, y: x / (y + 1e-5)),\n",
    "                      ('/', lambda x, y: y / (x + 1e-5)),\n",
    "                      ('-', lambda x, y: x - y),\n",
    "                      ('+', lambda x, y: x + y)]\n",
    "        for op_name, operation in operations:\n",
    "            new_col_name = f\"{col1}{op_name}{col2}\"\n",
    "            temp_df[new_col_name] = operation(Xtrain[col1], Xtrain[col2])\n",
    "            temp_df_test[new_col_name] = operation(Xtest[col1], Xtest[col2])\n",
    "\n",
    "        return temp_df, temp_df_test\n",
    "    # Initialisez une liste pour stocker les résultats\n",
    "    results = []\n",
    "    # Boucle sur les colonnes avec tqdm pour afficher une barre de progression\n",
    "    for i in tqdm(range(len(cols)), desc='Generating Features'):\n",
    "        col1 = cols[i]\n",
    "        temp_cols = cols[i+1:]\n",
    "        # Appel à generate_features pour chaque paire de colonnes\n",
    "        for col2 in temp_cols:\n",
    "            temp_df, temp_df_test = generate_features(col1, col2)\n",
    "            results.append((temp_df, temp_df_test))\n",
    "    for temp_df, temp_df_test in results:\n",
    "        for column in temp_df.columns:\n",
    "            scores = []\n",
    "            for train_index, val_index in skf.split(Xtrain, Ytrain):\n",
    "                X_train, X_val = temp_df[column].iloc[train_index].values.reshape(-1, 1), temp_df[column].iloc[val_index].values.reshape(-1, 1)\n",
    "                y_train, y_val = Ytrain.astype(int).iloc[train_index], Ytrain.astype(int).iloc[val_index]   \n",
    "                model = HistGradientBoostingClassifier(max_iter=300, learning_rate=0.02, max_depth=6, random_state=42)\n",
    "                model.fit(X_train, y_train)  \n",
    "                y_pred = model.predict_proba(X_val)[:,1]\n",
    "                score = roc_auc_score( y_val, y_pred)\n",
    "                scores.append(score)    \n",
    "            mean_score = np.mean(scores)\n",
    "            if mean_score > best_score:\n",
    "                new_col_name = temp_df[column].name\n",
    "                corr_with_other_cols = Xtrain.corrwith(temp_df[column])\n",
    "                if (corr_with_other_cols.abs().max() < 0.9 or best_score) and corr_with_other_cols.abs().max() != 1:\n",
    "                    Xtrain[new_col_name] = temp_df[column]\n",
    "                    Xtest[new_col_name] = temp_df_test[column]\n",
    "                    new_cols.append(new_col_name)\n",
    "                    print(f\"Added column '{new_col_name}' with ROC AUC Score: {mean_score:.4f} & Correlation {corr_with_other_cols.abs().max():.4f}\")\n",
    "    return  Xtrain,  Xtest, new_cols\n",
    "\n",
    "def post_processor(train, test):\n",
    "    # Identifie les colonnes en double dans l'ensemble de données d'entraînement\n",
    "    duplicate_columns = train.loc[:, train.columns.duplicated()].columns\n",
    "    \n",
    "    # Supprime les colonnes en double de l'ensemble de données d'entraînement et de test\n",
    "    train = train.drop(columns=duplicate_columns)\n",
    "    test = test.drop(columns=duplicate_columns)\n",
    "    return train, test\n",
    "             \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
