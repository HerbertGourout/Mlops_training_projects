{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6c9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import optuna\n",
    "import gc\n",
    "from prettytable import PrettyTable\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from numexpr import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import PowerTransformer, FunctionTransformer, MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import warnings\n",
    "from scipy.stats import pearsonr, chi2_contingency, pointbiserialr\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ea84e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Jepssen\\\\0_Mlops\\\\Untitled Folder'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b93d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset (filename):\n",
    "    file_path =os.path.join(os.getcwd(),filename)\n",
    "    data  = pd.read_csv(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57b36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset ('train.csv')\n",
    "test = load_dataset ('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37ec9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165034, 14) (110023, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c5a909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender',\n",
       "       'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f776495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que 'train' et 'test' sont déjà chargés\n",
    "#train.drop(columns=[\"id\", \"Surname\", \"CustomerId\"], inplace=True)\n",
    "#test.drop(columns=[\"id\", \"Surname\"], inplace=True)\n",
    "y_target = train['Exited']\n",
    "Xtrain_copy = train.drop(columns=['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52bddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca04d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que 'train' et 'test' sont déjà chargés\n",
    "# Diviser les données\n",
    "#train.drop(columns=[\"id\", \"Surname\", \"CustomerId\"], inplace=True)\n",
    "#test.drop(columns=[\"id\", \"Surname\", \"CustomerId\"], inplace=True)\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(train.drop(columns=['Exited']),\n",
    "                                                train['Exited'],\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=0,\n",
    "                                                stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "734f1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DropColumns Transformer\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, errors='ignore')\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [col for col in input_features if col not in self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0bc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FillMissing Transformer\n",
    "class FillMissing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target, max_iterations=10):\n",
    "        self.target = target\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        train = X.copy()\n",
    "        if self.target in train.columns:\n",
    "            train = train.drop(columns=self.target)\n",
    "        \n",
    "        df = pd.concat([train, y], axis=\"rows\").reset_index(drop=True)\n",
    "        numeric_features = df.select_dtypes(include=np.number).columns\n",
    "        categorical_features = df.select_dtypes(include='object').columns\n",
    "\n",
    "        if len(numeric_features) > 0:\n",
    "            imputer_numeric = KNNImputer()\n",
    "            df[numeric_features] = imputer_numeric.fit_transform(df[numeric_features])\n",
    "        \n",
    "        if len(categorical_features) > 0:\n",
    "            for feature in categorical_features:\n",
    "                mode_value = df[feature].mode()[0]\n",
    "                df[feature] = df[feature].fillna(mode_value)\n",
    "        \n",
    "        return df.iloc[:train.shape[0]].reset_index(drop=True)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return input_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "193656f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HandleRareCategories Transformer\n",
    "class HandleRareCategories(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_list):\n",
    "        self.col_list = col_list\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.common_values = {}\n",
    "        for col in self.col_list:\n",
    "            self.common_values[col] = set(X[col].value_counts().index)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        for col in self.col_list:\n",
    "            common = self.common_values[col]\n",
    "            df[col] = df[col].apply(lambda x: nearest_val(x, common) if x not in common else x)\n",
    "        return df\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return input_features\n",
    "\n",
    "def nearest_val(target, common):\n",
    "    return min(common, key=lambda x: abs(x - target))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2342fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoderCustom Transformer\n",
    "class OneHotEncoderCustom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols_to_encode, min_percentage=0.0):\n",
    "        self.cols_to_encode = cols_to_encode\n",
    "        self.min_percentage = min_percentage\n",
    "        self.feature_names_out_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.train_value_counts_ = {}\n",
    "        self.min_freq_category_ = {}\n",
    "        self.min_freq_percentage_ = {}\n",
    "\n",
    "        for col in self.cols_to_encode:\n",
    "            value_counts = X[col].value_counts(normalize=True)\n",
    "            self.train_value_counts_[col] = value_counts\n",
    "            self.min_freq_category_[col] = value_counts.idxmin()\n",
    "            self.min_freq_percentage_[col] = value_counts.min()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_encode = pd.DataFrame(index=X.index)\n",
    "        for col in self.cols_to_encode:\n",
    "            ohe_prefix = f\"{col}_OHE\"\n",
    "            value_counts = self.train_value_counts_[col]\n",
    "            min_freq_category = self.min_freq_category_[col]\n",
    "            min_freq_category_name = f\"{ohe_prefix}_{min_freq_category}\"\n",
    "\n",
    "            if self.min_freq_percentage_[col] < self.min_percentage:\n",
    "                dummies = pd.get_dummies(X[col], prefix=ohe_prefix, prefix_sep='_')\n",
    "                dummies.drop(columns=min_freq_category_name, errors='ignore', inplace=True)\n",
    "            else:\n",
    "                dummies = pd.get_dummies(X[col], prefix=ohe_prefix, prefix_sep='_')\n",
    "\n",
    "            X_encode = pd.concat([X_encode, dummies], axis=1)\n",
    "        \n",
    "        non_encoded_cols = X.drop(columns=self.cols_to_encode)\n",
    "        X_combined = pd.concat([non_encoded_cols, X_encode], axis=1)\n",
    "        self.feature_names_out_ = X_combined.columns\n",
    "        \n",
    "        return X_combined\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        encoded_cols = []\n",
    "        for col in self.cols_to_encode:\n",
    "            for value in self.train_value_counts_[col].index:\n",
    "                encoded_cols.append(f\"{col}_OHE_{value}\")\n",
    "        return encoded_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6bc449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, pipeline, Xtrain, Ytrain, Xtest, Ytest):\n",
    "        self.pipeline = pipeline\n",
    "        self.Xtrain = Xtrain\n",
    "        self.Ytrain = Ytrain\n",
    "        self.Xtest = Xtest\n",
    "        self.Ytest = Ytest\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.best_models = {}\n",
    "        self.column_names = []\n",
    "        \n",
    "    def encode_labels(self):\n",
    "        \"\"\"\n",
    "        Encode les étiquettes de classe en entiers.\n",
    "        \"\"\"\n",
    "        self.Ytrain = self.label_encoder.fit_transform(self.Ytrain.ravel())\n",
    "        self.Ytest = self.label_encoder.transform(self.Ytest.ravel())\n",
    "    \n",
    "    def train_models(self):\n",
    "        \"\"\"\n",
    "        Entraîne les modèles de base sur les données d'entraînement et trouve les meilleurs hyperparamètres.\n",
    "        \"\"\"\n",
    "        # Initialiser les classificateurs\n",
    "        adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "        extratrees_clf = ExtraTreesClassifier(random_state=42)\n",
    "        gradientboost_clf = GradientBoostingClassifier(random_state=42)\n",
    "        randomforest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Définir les grilles de recherche pour les hyperparamètres\n",
    "        adaboost_params = {'n_estimators': [50, 100]}\n",
    "        extratrees_params = {'n_estimators': [50, 100]}\n",
    "        gradientboost_params = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "        randomforest_params = {'n_estimators': [50, 100]}\n",
    "        \n",
    "        # Initialiser les objets de recherche sur grille\n",
    "        adaboost_grid = GridSearchCV(adaboost_clf, adaboost_params, cv=3, scoring='accuracy')\n",
    "        extratrees_grid = GridSearchCV(extratrees_clf, extratrees_params, cv=5, scoring='accuracy')\n",
    "        gradientboost_grid = GridSearchCV(gradientboost_clf, gradientboost_params, cv=5, scoring='accuracy')\n",
    "        randomforest_grid = GridSearchCV(randomforest_clf, randomforest_params, cv=5, scoring='accuracy')\n",
    "\n",
    "        # Effectuer la recherche sur grille pour chaque classificateur\n",
    "        adaboost_grid.fit(self.Xtrain, self.Ytrain)\n",
    "        extratrees_grid.fit(self.Xtrain, self.Ytrain)\n",
    "        gradientboost_grid.fit(self.Xtrain, self.Ytrain)\n",
    "        randomforest_grid.fit(self.Xtrain, self.Ytrain)\n",
    "\n",
    "        # Stocker les meilleurs modèles\n",
    "        self.best_models['adaboost'] = adaboost_grid.best_estimator_\n",
    "        self.best_models['extratrees'] = extratrees_grid.best_estimator_\n",
    "        self.best_models['gradientboost'] = gradientboost_grid.best_estimator_\n",
    "        self.best_models['randomforest'] = randomforest_grid.best_estimator_\n",
    "        \n",
    "    def evaluate_models(self):\n",
    "        \"\"\"\n",
    "        Évalue les modèles de base sur l'ensemble de validation.\n",
    "        \"\"\"\n",
    "        for name, model in self.best_models.items():\n",
    "            test_pred = model.predict(self.Xtest)\n",
    "            test_accuracy = accuracy_score(self.Ytest, test_pred)\n",
    "            print(f\"{name.capitalize()} Accuracy on validation set: {test_accuracy}\")\n",
    "            \n",
    "    def train_stacking_model(self):\n",
    "        \"\"\"\n",
    "        Entraîne le modèle de stacking en utilisant les modèles de base comme estimateurs.\n",
    "        \"\"\"\n",
    "        base_classifiers = [(name, model) for name, model in self.best_models.items()]\n",
    "        self.stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=LogisticRegression())\n",
    "        self.stacking_clf.fit(self.Xtrain, self.Ytrain)\n",
    "        \n",
    "    def evaluate_stacking_model(self):\n",
    "        \"\"\"\n",
    "        Évalue le modèle de stacking sur l'ensemble de test.\n",
    "        \"\"\"\n",
    "        stacking_pred = self.stacking_clf.predict(self.Xtest)\n",
    "        stacking_accuracy = accuracy_score(self.Ytest, stacking_pred)\n",
    "        print(\"Stacking Accuracy on test set:\", stacking_accuracy)\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Exécute le processus complet d'encodage, d'entraînement, d'évaluation et de test.\n",
    "        \"\"\"\n",
    "        # Transformation des données d'entraînement et de test\n",
    "        self.Xtrain_enc = self.pipeline.fit_transform(self.Xtrain, self.Ytrain)\n",
    "        self.Xtest_enc = self.pipeline.transform(self.Xtest)\n",
    "        \n",
    "        # Récupérer les noms de colonnes après transformation\n",
    "        self.column_names = self.pipeline.named_steps['preprocessor'].get_feature_names_out(input_features=self.Xtrain.columns)\n",
    "        self.column_names = [col.replace('remainder__', '').replace('one_hot_encoding__', '') for col in self.column_names]\n",
    "        \n",
    "        # Conversion des données transformées en DataFrame avec les noms de colonnes\n",
    "        self.Xtrain = pd.DataFrame(self.Xtrain_enc, columns=self.column_names)\n",
    "        self.Xtest = pd.DataFrame(self.Xtest_enc, columns=self.column_names)\n",
    "        \n",
    "        # Encodage des étiquettes\n",
    "        self.encode_labels()\n",
    "        \n",
    "        # Entraînement et évaluation des modèles de base\n",
    "        self.train_models()\n",
    "        self.evaluate_models()\n",
    "        \n",
    "        # Entraînement et évaluation du modèle de stacking\n",
    "        self.train_stacking_model()\n",
    "        self.evaluate_stacking_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25497a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7883d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes à transformer\n",
    "cont_cols = [\"CreditScore\", \"Age\", \"Balance\", \"EstimatedSalary\"]\n",
    "cat_cols_to_encode = [\"Geography\", \"Tenure\", \"NumOfProducts\", \"Gender\"]\n",
    "cols_rare = [\"Tenure\", \"NumOfProducts\"]\n",
    "columns_drop =[\"id\", \"Surname\", \"CustomerId\"]\n",
    "\n",
    "# Exemple de pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', DropColumns(columns=[\"id\", \"Surname\", \"CustomerId\"]), columns_drop),\n",
    "        ('fill_missing', FillMissing(target='Exited'), []),\n",
    "        ('handle_rare_categories', HandleRareCategories(col_list=cols_rare), []),\n",
    "        ('one_hot_encoding', OneHotEncoderCustom(cols_to_encode=cat_cols_to_encode), cat_cols_to_encode)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5c227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa434ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f33f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Accuracy on validation set: 0.8620898597267246\n",
      "Extratrees Accuracy on validation set: 0.8506983367164541\n",
      "Gradientboost Accuracy on validation set: 0.8653618929318023\n",
      "Randomforest Accuracy on validation set: 0.8577574453903717\n",
      "Stacking Accuracy on test set: 0.8655436725543066\n"
     ]
    }
   ],
   "source": [
    "# Initialiser et exécuter le processus\n",
    "model_trainer = ModelTrainer(pipeline, Xtrain, Ytrain, Xtest, Ytest)\n",
    "model_trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338393e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb01b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac0b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les noms de colonnes après transformation\n",
    "column_names = pipeline.named_steps['preprocessor'].get_feature_names_out(input_features=Xtrain.columns)\n",
    "# Supprimer les préfixes remainder__ et one_hot_encoding__\n",
    "column_names = [col.replace('remainder__', '').replace('one_hot_encoding__', '') for col in column_names]\n",
    "# Afficher les noms de colonnes sans les préfixes\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8cd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance de LabelEncoderTransformer\n",
    "label_encoder = LabelEncoderTransformer()\n",
    "# Encoder les étiquettes de classe\n",
    "Ytrain_encoded = label_encoder.fit_transform(Ytrain)\n",
    "Ytest_encoded = label_encoder.transform(Ytest)\n",
    "set(Ytest_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee432a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb56730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b5f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain= pd.DataFrame(Xtrain_transformed, columns=column_names)\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest= pd.DataFrame(Xtest_transformed, columns=column_names)\n",
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5478e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b07e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642bfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4d02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les classificateurs\n",
    "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "extratrees_clf = ExtraTreesClassifier(random_state=42)\n",
    "gradientboost_clf = GradientBoostingClassifier(random_state=42)\n",
    "randomforest_clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba814a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les grilles de recherche pour les hyperparamètres\n",
    "adaboost_params = {'n_estimators': [50, 100, 200]}\n",
    "extratrees_params = {'n_estimators': [50, 100, 200]}\n",
    "gradientboost_params = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.5]}\n",
    "randomforest_params = {'n_estimators': [50, 100, 200]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a82a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les objets de recherche sur grille\n",
    "adaboost_grid = GridSearchCV(adaboost_clf, adaboost_params, cv=5, scoring='accuracy')\n",
    "extratrees_grid = GridSearchCV(extratrees_clf, extratrees_params, cv=5, scoring='accuracy')\n",
    "gradientboost_grid = GridSearchCV(gradientboost_clf, gradientboost_params, cv=5, scoring='accuracy')\n",
    "randomforest_grid = GridSearchCV(randomforest_clf, randomforest_params, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e740b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effectuer la recherche sur grille pour chaque classificateur\n",
    "adaboost_grid.fit(Xtrain, Ytrain)\n",
    "extratrees_grid.fit(Xtrain, Ytrain)\n",
    "gradientboost_grid.fit(Xtrain, Ytrain)\n",
    "randomforest_grid.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb760480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les meilleurs modèles\n",
    "best_adaboost_clf = adaboost_grid.best_estimator_\n",
    "best_extratrees_clf = extratrees_grid.best_estimator_\n",
    "best_gradientboost_clf = gradientboost_grid.best_estimator_\n",
    "best_randomforest_clf = randomforest_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions sur l'ensemble de test avec les meilleurs modèles\n",
    "adaboost_test_pred = best_adaboost_clf.predict(Xtest)\n",
    "extratrees_test_pred = best_extratrees_clf.predict(Xtest)\n",
    "gradientboost_test_pred = best_gradientboost_clf.predict(Xtest)\n",
    "randomforest_test_pred = best_randomforest_clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2000530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance des meilleurs modèles sur l'ensemble de test\n",
    "adaboost_test_accuracy = accuracy_score(Ytest, adaboost_test_pred)\n",
    "extratrees_test_accuracy = accuracy_score(Ytest, extratrees_test_pred)\n",
    "gradientboost_test_accuracy = accuracy_score(Ytest, gradientboost_test_pred)\n",
    "randomforest_test_accuracy = accuracy_score(Ytest, randomforest_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AdaBoost Accuracy on test set:\", adaboost_test_accuracy)\n",
    "print(\"ExtraTrees Accuracy on test set:\", extratrees_test_accuracy)\n",
    "print(\"GradientBoost Accuracy on test set:\", gradientboost_test_accuracy)\n",
    "print(\"RandomForest Accuracy on test set:\", randomforest_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Définir les classificateurs de base pour le stacking\n",
    "base_classifiers = [\n",
    "    ('adaboost', best_adaboost_clf),\n",
    "    ('extratrees', best_extratrees_clf),\n",
    "    ('gradientboost', best_gradientboost_clf),\n",
    "    ('randomforest', best_randomforest_clf)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le classificateur de stacking avec une régression logistique comme estimateur final\n",
    "stacking_clf = StackingClassifier(estimators=base_classifiers, final_estimator=LogisticRegression())\n",
    "# Entraîner le classificateur de stacking sur l'ensemble d'entraînement et de validation combiné\n",
    "stacking_clf.fit(Xtrain, Ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions sur l'ensemble de test avec le classificateur de stacking\n",
    "stacking_test_pred = stacking_clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance du classificateur de stacking sur l'ensemble de test\n",
    "stacking_test_accuracy = accuracy_score(Ytest, stacking_test_pred)\n",
    "print(\"Stacking Accuracy on test set:\", stacking_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "model_trainer = ModelTrainer(Xtrain, Ytrain, Xtest, Ytest)\n",
    "model_trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbefc1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
